# amazon-data-web-scrapping
So in this web scrapping project, I have utilized BeautifulSoup, Numpy, and Panda libraries which come inbuilt with the python programming language and they are few of the most powerful libraries used in python. With the help of the requests library, it was easy for us to gather information from the HTML source from the amazon website.
By utilizing BeautifulSoup (html.parser), we were able to modify the raw HTML file to a readable format. After we converted the raw file into readable HTML format, we used the find_all function with BeautifulSoup and scrap all the links from the amazon website. We store all the links in a list and we create 5 different lists to store the values of title, price, ratings, total reviews, and the availability of each item. Later, we append 'https://www.amazon.com' to each link scrapped from the <a href> tag; which would be useful to scrap all the required data into each list created earlier.
In the python code, I had to remove an element from the links list, which was a sponsored link in the amazon website. The reason for removing the link is it already had the appended 'https://www.amazon.com' in the <a href> tag.
Once all the required data was scrapped and included in the created lists, we used pandas to create a DataFrame and organize the data. Once the data was organized in a DataFrame with the pandas library's help, we extracted it into a CSV file and saved it on the local computer.
